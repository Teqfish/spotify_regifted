{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b653f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import string\n",
    "import pprint as pp\n",
    "import zipfile as zf\n",
    "\n",
    "path = '/Users/beng/code/spotify/datasets holding' # THIS WILL BE THE PATH OF THE UPLOAD BOX\n",
    "ext_json = '.json'\n",
    "ext_zip = '.zip'\n",
    "name = 'beng'  # input('What is your name?\\n')\n",
    "files = []\n",
    "\n",
    "# check for zipped files\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(ext_zip):\n",
    "        file.extractall(path)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(ext_json) and 'Audio' in file or file.endswith(ext_json) and 'audiobook' in file:\n",
    "        files.append(file)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "    df = pd.read_json(os.path.join(path, file))\n",
    "    df_list.append(df)\n",
    "\n",
    "total = 0\n",
    "for data in df_list:\n",
    "    total = total + len(data)\n",
    "# print(f'Merged dataset should have {total} rows')\n",
    "\n",
    "df_mega = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# CLEANING\n",
    "\n",
    "# filter out rows with no listen time\n",
    "df_mega = df_mega[df_mega['ms_played'] != 0]\n",
    "# transform ms to seconds\n",
    "df_mega['seconds_played'] = df_mega['ms_played'] / 1000\n",
    "# transform seconds to minutes\n",
    "df_mega['minutes_played'] = round(df_mega['seconds_played'] / 60, 2)\n",
    "# rename columns\n",
    "df_mega = df_mega.rename(columns={'ts': 'datetime'})\n",
    "df_mega = df_mega.rename(columns={'conn_country': 'country'})\n",
    "df_mega = df_mega.rename(columns={'master_metadata_track_name': 'track_name'})\n",
    "df_mega = df_mega.rename(columns={'master_metadata_album_artist_name': 'artist_name'})\n",
    "df_mega = df_mega.rename(columns={'master_metadata_album_album_name': 'album_name'})\n",
    "# cast datetime to datetime\n",
    "df_mega['datetime'] = pd.to_datetime(df_mega['datetime'])\n",
    "\n",
    "\n",
    "\n",
    "# add categories for music, audio and audiobook\n",
    "\n",
    "def categorise(row):\n",
    "    if pd.isnull(row['track_name']):\n",
    "        if pd.isnull(row['episode_show_name']):\n",
    "            return 'audiobook'\n",
    "        else:\n",
    "            return 'podcast'\n",
    "    else:\n",
    "        if pd.isnull(row['episode_show_name']):\n",
    "            return 'music'\n",
    "        else:\n",
    "            return row['no category']\n",
    "\n",
    "\n",
    "df_mega['category'] = df_mega.apply(categorise, axis=1)\n",
    "\n",
    "# drop unecessary columns\n",
    "df_mega = df_mega.drop(columns=['offline','offline_timestamp','incognito_mode','endTime','audiobookName','chapterName',\n",
    "                                'authorName','msPlayed', \"platform\", \"ip_addr\"])\n",
    "# drop nulls\n",
    "df_mega = df_mega[~df_mega[['track_name', 'episode_name', 'audiobook_title']].isnull().all(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //////////////////////  ETL and EDA app for listening habits using Spotify streaming  /////////////////////////\n",
    "# //////////////////////   history and Discogs API for genre and style classification.  /////////////////////////\n",
    "# ////////////////////// There might also be some sexy feature analysis using Essentia. /////////////////////////\n",
    "\n",
    "# 1. Import\n",
    "# 2. Unpack, merge, and clean Spotify data\n",
    "# 3. Get genre data from Discogs API\n",
    "# 4. Top 20 personal stats\n",
    "# 5. Top 100 artists by month over last 15 years\n",
    "# 6. Visualize (DASH, STREAMLIT?)\n",
    "\n",
    "# APP features   - upload zip file\n",
    "#                - date range, genre, style, artist filters\n",
    "#                - ms/day over time chart\n",
    "#                - genre/style/artist bar chart\n",
    "#                - some kind of histogram\n",
    "# STRETCH  - dates and description of all salient moments during lockdown\n",
    "# LUNGE    - Analyse audio features using Essentia\n",
    "\n",
    "# Should this all be split into functions or seperate files?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ////////////////////// Import everything and anything. RAM is free. //////////////////////\n",
    "import zipfile\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ////////////////////// Unpacking, merging, and cleaning Spotify data //////////////////////\n",
    "\n",
    "# Location of zipped streaming history\n",
    "zipped_dir = \"/Users/admin/Desktop/my_spotify_data.zip\"\n",
    "unzipped_dir = \"/Users/admin/Desktop/my_spotify_data\"\n",
    "\n",
    "# Unzipping the file\n",
    "zf = zipfile.ZipFile(zipped_dir)\n",
    "zf.extractall(unzipped_dir)\n",
    "\n",
    "# Empty list of json dfs\n",
    "dfs = []\n",
    "\n",
    "#Search unzipped folder for jsons containing \"audio\"\n",
    "for root, dirs, files in os.walk(unzipped_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.json') and 'audio' in file.lower():\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(f\"Reading: {file_path}\")\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            try:              \n",
    "                df = pd.read_json(file_path)\n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "# BIRTH OF THE MEGAFRAME <<<<<<<<<<<<<<<<<<<\n",
    "if dfs:\n",
    "    df_mega = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Combined DataFrame shape: {df_mega.shape}\")\n",
    "else:\n",
    "    print(\"No matching JSON files found.\")\n",
    "\n",
    "# Cheeky CSV export\n",
    "df_mega.to_csv('/Users/admin/Desktop/spotify_streaming_history_full.csv', index=False)\n",
    "\n",
    "# Rename columns\n",
    "df_mega = df_mega.rename(columns={'master_metadata_album_artist_name': 'artist'})\n",
    "df_mega = df_mega.rename(columns={'master_metadata_album_album_name': 'album'})\n",
    "df_mega = df_mega.rename(columns={'master_metadata_track_name': 'track'})\n",
    "df_mega = df_mega.rename(columns={'ts': 'datetime'})\n",
    "\n",
    "# date_time conversion\n",
    "df_mega['datetime'] = pd.to_datetime(df_mega['datetime'])\n",
    "\n",
    "# Drop columns\n",
    "df_mega = df_mega.drop(columns=['shuffle', 'skipped', 'offline', 'offline_timestamp', 'incognito_mode', 'episode_name', 'episode_show_name', 'spotify_episode_uri', 'audiobook_title', 'audiobook_uri', 'audiobook_chapter_uri', 'audiobook_chapter_title'])\n",
    "\n",
    "# Blindly drop nulls\n",
    "df_mega.dropna(subset=['track'], inplace=True)\n",
    "\n",
    "# Remove $ in artist names\n",
    "df_mega_S = df_mega[df_mega[\"artist\"].str.contains(\"$\",case=False,regex=False)]\n",
    "for i in df_mega_S.index:\n",
    "    df_mega.at[i, \"artist\"] = df_mega.at[i, \"artist\"].replace(\"$\", \"S\")\n",
    "\n",
    "# Remove $ in album names\n",
    "df_mega_S = df_mega[df_mega[\"album\"].str.contains(\"$\",case=False,regex=False)]\n",
    "for i in df_mega_S.index:\n",
    "    df_mega.at[i, \"album\"] = df_mega.at[i, \"album\"].replace(\"$\", \"S\")\n",
    "\n",
    "# Remove $ in track names\n",
    "df_mega_S = df_mega[df_mega[\"track\"].str.contains(\"$\",case=False,regex=False)]\n",
    "for i in df_mega_S.index:\n",
    "    df_mega.at[i, \"track\"] = df_mega.at[i, \"track\"].replace(\"$\", \"S\")\n",
    "\n",
    "# Remove inexplicable outlier!!!\n",
    "df_mega = df_mega[df_mega['artist'] != 'Travis Scott']\n",
    "\n",
    "\n",
    "# Change ms_played to seconds\n",
    "# Music vs Podcast segmentation column\n",
    "\n",
    "\n",
    "# ////////////////////// Let's get some genre data from Discogs API //////////////////////\n",
    "\n",
    "# Discogs API search URL\n",
    "url = \"https://api.discogs.com/database/search\"\n",
    "\n",
    "# Empty list for genre and style\n",
    "genre = []\n",
    "style = []\n",
    "\n",
    "# Artist only df\n",
    "df_artists = df_mega[\"artist\"].unique()\n",
    "\n",
    "for i, search_artist in enumerate(df_artists):\n",
    "    if i >= 100:  # Limit to first 100 unique artists\n",
    "        break\n",
    "    print(f'Searching for {search_artist}. Elapsed time: {round(response.elapsed.total_seconds() * 1000),0}ms, Response code: {response.status_code}')\n",
    "    \n",
    "    # Search for a specific artist\n",
    "    querystring = {\"artist\":search_artist,\"key\":\"htNKzMgqirnVxMvtJhVZ\",\"secret\":\"CuvkyucamfZWJXamQBoJPfoFYDJueIHn\"}\n",
    "\n",
    "    # Got all this off Insomnia\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "        \"cookie\": \"__cf_bm=r_6Jv_2Qu_E6bkBOgxlZSlNoz0HiAnV.fq5LFUhrkoM-1747773282-1.0.1.1-RhXxhPlu62Dtfb2wTOh1t1OjM8uY3L.kK6Bsbe90WrbUUoZlZ9cfrXSPhjp7Fm7XRALeH4coK7P9cAMT8iYqEepTpI2BHxR9kAg5TzLagL8\",\n",
    "        \"User-Agent\": \"insomnia/11.1.0\"\n",
    "    }\n",
    "\n",
    "    # Filter response to just results and create JSON\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "    response_json = response.json()[\"results\"]\n",
    "\n",
    "    # Check if the response is empty\n",
    "    if not response_json:\n",
    "        print(f\"No results found for artist: {search_artist}\")\n",
    "        genre.append(None)\n",
    "        style.append(None)\n",
    "        continue\n",
    "\n",
    "    # Append genre and style to lists\n",
    "    genre.append(response_json[0].get(\"genre\"))\n",
    "    style.append(response_json[0].get(\"style\"))\n",
    "\n",
    "    # Add genre and style to MEGAFRAME\n",
    "    df_mega.loc[df_mega['artist'] == search_artist, 'genre'] = genre\n",
    "    df_mega.loc[df_mega['artist'] == search_artist, 'style'] = style\n",
    "\n",
    "    # Don't rinse the API\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ////////////////////// Top 20 stats //////////////////////\n",
    "\n",
    "# Top 20 artists by ms listened\n",
    "top_20_artists_ms = df_mega.groupby('artist')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 albums by ms listened\n",
    "top_20_albums_ms = df_mega.groupby('album')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 tracks by ms listened\n",
    "top_20_tracks_ms = df_mega.groupby('track')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 genres by ms listened\n",
    "top_20_genres_ms = df_mega.groupby('genre')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 styles by ms listened\n",
    "top_20_styles_ms = df_mega.groupby('style')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "\n",
    "# Top 20 artists by number of tracks listened to\n",
    "top_20_artists_tracks = df_mega.groupby('artist')['ms_played'].count().nlargest(20).reset_index()\n",
    "\n",
    "#Top 20 artists by number of albums listened to\n",
    "top_20_artists_albums = df_mega.groupby('artist')['album'].nunique().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 albums by number of times listened to\n",
    "top_20_albums = df_mega.groupby('album')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 tracks by number of times listened to\n",
    "top_20_tracks = df_mega.groupby('track')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "# Top 20 artists by number of times listened to\n",
    "top_20_artists = df_mega.groupby('artist')['ms_played'].sum().nlargest(20).reset_index()\n",
    "\n",
    "\n",
    "# Top 20 most common genres\n",
    "top_20_genres_count = df_mega['genre'].value_counts().nlargest(20).reset_index()\n",
    "top_20_genres_count.columns = ['genre', 'count']\n",
    "\n",
    "# Top 20 most common styles\n",
    "top_20_styles_count = df_mega['style'].value_counts().nlargest(20).reset_index()\n",
    "top_20_styles_count.columns = ['style', 'count']\n",
    "\n",
    "# Top 20 most common artists\n",
    "top_20_artists_count = df_mega['artist'].value_counts().nlargest(20).reset_index()\n",
    "top_20_artists_count.columns = ['artist', 'count']\n",
    "\n",
    "# Top 20 most common albums\n",
    "top_20_albums_count = df_mega['album'].value_counts().nlargest(20).reset_index()\n",
    "top_20_albums_count.columns = ['album', 'count']\n",
    "\n",
    "# Top 20 most common tracks\n",
    "top_20_tracks_count = df_mega['track'].value_counts().nlargest(20).reset_index()\n",
    "top_20_tracks_count.columns = ['track', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16f4aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# data analysis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#%% read files\u001b[39;00m\n\u001b[32m     23\u001b[39m os.chdir(\u001b[33m\"\u001b[39m\u001b[33mDEFINE PATH\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 26 11:52:13 2025\n",
    "\n",
    "@author: J\n",
    "\"\"\"\n",
    "\n",
    "#%% import libraries\n",
    "\n",
    "# directory\n",
    "import os\n",
    "\n",
    "\n",
    "# file reading\n",
    "import json\n",
    "\n",
    "# data analysis\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#%% read files\n",
    "\n",
    "os.chdir(\"DEFINE PATH\")\n",
    "\n",
    "# df to read files into\n",
    "ds = []\n",
    "\n",
    "# Iterate over files in directory\n",
    "for name in os.listdir():\n",
    "    if \"json\" and \"Audio\" in name:\n",
    "        with open(name, 'r', encoding=\"utf8\") as file:\n",
    "            ds += json.load(file)\n",
    "            \n",
    "# unwrap list of dictionaries into dataframe\n",
    "df = pd.DataFrame(ds)\n",
    "#%% clean and split by music and podcasts\n",
    "\n",
    "# overview\n",
    "df.info()\n",
    "\n",
    "# remove audiobook columns (all null)\n",
    "df = df.loc[:, [\"audiobook\" not in name for name in df.columns]]\n",
    "\n",
    "# columns not used\n",
    "df = df.drop([\"platform\", \"ip_addr\", \"offline\", \"offline_timestamp\", \"incognito_mode\"], axis = 1)\n",
    "\n",
    "# convert time stamp to datetime\n",
    "df[\"ts\"] = pd.to_datetime(df[\"ts\"], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# convert ms_played to min_played\n",
    "df = df.rename(columns = {\"ms_played\":\"min_played\"})\n",
    "df[\"min_played\"] = df.min_played.map(lambda x: x/60000)\n",
    "\n",
    "## split music and podcasts and remove irrelevant columns, rename columns\n",
    "# podcasts\n",
    "df_pod = df[df[\"master_metadata_track_name\"].isna()]\n",
    "df_pod = df_pod.loc[:, [\"metadata\" not in name for name in df.columns]] # song associated columns\n",
    "df_pod = df_pod.drop(\"spotify_track_uri\", axis = 1) # song associated column\n",
    "df_pod = df_pod.rename(columns = {\"conn_country\" : \"country_played\"})\n",
    "\n",
    "\n",
    "# music\n",
    "df_mu = df[df[\"episode_show_name\"].isna()]\n",
    "df_mu = df_mu.loc[:, [\"episode\" not in name for name in df.columns]]\n",
    "df_mu = df_mu.rename(columns = {\"conn_country\": \"country_played\",\n",
    "                                \"master_metadata_track_name\" : \"track_name\",\n",
    "                                \"master_metadata_album_artist_name\": \"artist_name\",\n",
    "                                \"master_metadata_album_album_name\" : \"album_name\"})\n",
    "\n",
    "# check dataframes\n",
    "# df_pod.info()\n",
    "# df_mu.info() \n",
    "\n",
    "#%% remove artists with fewer than 10 plays\n",
    "\n",
    "min_filter = df_mu.artist_name.value_counts().sort_values()\n",
    "min_filter = min_filter[min_filter >= 10]\n",
    "min_filter = list(min_filter.index)\n",
    "df_mu = df_mu[df_mu[\"artist_name\"].isin(min_filter)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
