#%% import libraries

from google.cloud import bigquery
import pandas_gbq
import os

# set directory if needed
os.chdir("ENTER DIRECTORY")

#%% define functions 

###
"""
setting up GBQ access - argument is the service account json
run function once (with service account json as argument) to initiate connection
"""
def set_up_gbq(key_path):
    bigquery.Client.from_service_account_json(key_path)

###
"""
save dataframe to GBQ table:
data_frame = dataframe you want to upload
target_dataset = str of dataset eg "raw_data"
target_table = str of table name eg "artist"
"""
def save_to_gbq(data_frame, target_dataset, target_table):
    table_path = target_dataset + "." + target_table
    data_frame.to_gbq(table_path, project_id = "spotify-regifted", if_exists = "replace")
###

###
"""
download GBQ table into dataframe
dataset_id = str dataset from which to dowload eg "raw_data"
table_id = str of table name eg "artist"
REMEMBER TO SAVE INTO VARIABLE eg df_artist = get_from_gbq("raw_data","artist")
"""
def get_from_gbq(dataset_id, table_id):
    table_path = dataset_id + "." + table_id
    sql = f"""
    SELECT *
    FROM `spotify-regifted.{table_path}`
    """
    df = pandas_gbq.read_gbq(sql, project_id = "spotify-regifted", location = "EU")
    
    return df